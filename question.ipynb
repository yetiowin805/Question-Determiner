{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import spacy\n",
    "import textacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def isNegative(token,sentence):\n",
    "    \"\"\"\n",
    "    token,tokens.doc -> bool\n",
    "    Takes a token representing a word and a doc representing a sentence\n",
    "    Returns whether the word is negated in the sentence\n",
    "    \"\"\"\n",
    "    for word in sentence:\n",
    "        if word.dep_ == 'neg': #if word is a negation\n",
    "            if word.head==token: #check if it negates the desired word\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def inClause(token,sentence):\n",
    "    \"\"\"\n",
    "    token,tokens.doc -> bool\n",
    "    Takes a token representing a word and a doc representing a sentence\n",
    "    Returns whether the word is part of a subordinate clause rather than the main clause\n",
    "    However, clauses subordinated by certain verbs of knowing or asking are included with main clauses\n",
    "    \"\"\"\n",
    "    clausetypes = ['advcl','relcl','csubj','csubjpass','pcomp','xcomp','acl','aux']\n",
    "    knowing = ['know','understand','see','get']\n",
    "    asking = ['wonder']\n",
    "    while token.dep_ != 'ROOT':\n",
    "        if token.dep_ in clausetypes:\n",
    "            return True\n",
    "        if token.dep_ == 'ccomp' or token.dep_ == 'conj':\n",
    "            if token.head.lemma_ in knowing: #if it is a verb of knowing, only use negatives\n",
    "                return not isNegative(token.head,sentence)\n",
    "            if token.head.lemma_ in asking:\n",
    "                return False\n",
    "            return True\n",
    "        token=token.head\n",
    "    return token.pos_ != 'VERB' and token.pos_ != 'AUX' #phrase head should be a verb\n",
    "\n",
    "def isSubject(token):\n",
    "    \"\"\"\n",
    "    token -> bool\n",
    "    Takes a token representing a word\n",
    "    Returns whether the word is part of the noun phrase representing the subject of a sentence\n",
    "    \"\"\"\n",
    "    while token.dep_ != 'ROOT': #iterate until you get to the main verb\n",
    "        if token.dep_ == 'nsubj': #if you get to the head of the subject noun phrase first, then the original word was part of this phrase\n",
    "            return True\n",
    "        token = token.head\n",
    "    return False\n",
    "\n",
    "def inPhrase(token1, token2):\n",
    "    \"\"\"\n",
    "    token, token -> bool\n",
    "    Takes two tokens representing words in the same sentence\n",
    "    Returns whether the first word is in a phrase headed by the second\n",
    "    \"\"\"\n",
    "    while token1.dep_ != 'ROOT':\n",
    "        if token1==token2:\n",
    "            return True\n",
    "        token1=token1.head\n",
    "    if token1==token2:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def hasAux(token, sentence):\n",
    "    \"\"\"\n",
    "    token, tokens.doc -> bool\n",
    "    Takes a word and a sentences\n",
    "    Returns whether the word is modified by an auxiliary in the sentence (or is one)\n",
    "    \"\"\"\n",
    "    if token.pos_ == 'AUX':\n",
    "        return True\n",
    "    for word in sentence:\n",
    "        if inPhrase(word,token):\n",
    "            temp = word\n",
    "            while temp.dep_ != 'ROOT':\n",
    "                if temp.pos_ == 'AUX':\n",
    "                    return True\n",
    "                temp = temp.head\n",
    "    return False\n",
    "\n",
    "def isYNQuestion(sentence):\n",
    "    \"\"\"\n",
    "    tokens.doc -> bool\n",
    "    Takes a string representing a sentence\n",
    "    Returns whether the sentence is a yes or no question\n",
    "    \"\"\"\n",
    "    if sentence[0].pos_ == 'AUX': #yn questions start with an auxiliary verb\n",
    "        if isSubject(sentence[1]): #it is followed by the subject\n",
    "            if sentence[0].dep_=='aux':\n",
    "                return sentence[0].head.dep_ == 'ROOT' #eliminates some rare adverbial clauses\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def isWHQuestion(sentence):\n",
    "    \"\"\"\n",
    "    tokens.doc -> bool\n",
    "    Takes a string representing a sentence\n",
    "    Returns whether the sentence is a wh-question, i.e. who-what-where-when-why\n",
    "    \"\"\"\n",
    "    whwords = ['who', 'what', 'where', 'when', 'why', 'how', 'which', 'whose', 'whence', 'whither', 'whom']\n",
    "    for word in sentence:\n",
    "        if word.lemma_ in whwords: #for each wh-word, see if it is in the main clause\n",
    "            if inClause(word,sentence):\n",
    "                continue #if not, continue looking for wh-words\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def isQuestion(sentence):\n",
    "    \"\"\"\n",
    "    str -> bool\n",
    "    Takes a string representing a sentence\n",
    "    Returns whether the sentence is a question\n",
    "    \"\"\"\n",
    "    text = nlp(sentence) #split up sentence into words\n",
    "    if len(text)<3:\n",
    "        return False\n",
    "    return isYNQuestion(text) or isWHQuestion(text)\n",
    "\n",
    "def extractQuestions(text):\n",
    "    \"\"\"\n",
    "    .csv -> list\n",
    "    Takes a csv file with some sentences\n",
    "    Returns the subset of sentences that are questions as a list\n",
    "    \"\"\"\n",
    "    sentences = list(text)[0] #convert csv into list\n",
    "    questions = [] #output list of questions\n",
    "    for element in sentences:\n",
    "        if isQuestion(element): #check if the sentence is a question\n",
    "            questions.append(element) #if so, add it to the list\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from cleantext import clean\n",
    "\n",
    "def extractQuestionsStr(sentences):\n",
    "    \"\"\"\n",
    "    list -> list\n",
    "    Takes list with strings representing sentences\n",
    "    Returns the subset of sentences that are questions as a list\n",
    "    \"\"\"\n",
    "    questions = [] #output list of questions\n",
    "    for element in sentences:\n",
    "        if isQuestion(element): #check if the sentence is a question\n",
    "            questions.append(element) #if so, add it to the list\n",
    "    return questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
